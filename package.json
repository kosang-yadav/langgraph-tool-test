{
  "name": "mcp-ollama-test",
  "version": "1.1.1",
  "description": "just a second play with mcp server, but now will local model (llama 3.2) on ollama",
  "main": "index.js",
  "type": "module",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "keywords": [
    "llama3.2",
    "node.js"
  ],
  "author": "baka",
  "license": "ISC",
  "dependencies": {
    "@langchain/core": "^0.3.43",
    "@langchain/google-genai": "^0.2.3",
    "@langchain/langgraph": "^0.2.63",
    "@langchain/ollama": "^0.2.0",
    "dotenv": "^16.4.7",
    "langchain": "^0.3.21",
    "readline-sync": "^1.4.10",
    "zod": "^3.24.2"
  }
}
